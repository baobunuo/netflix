{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_nation\n",
    "%store -r df_series_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix_movies = pickle.load(open('df_netflix_movies','rb'))\n",
    "df_netflix_movies.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>years</th>\n",
       "      <th>plots</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb</th>\n",
       "      <th>runtime</th>\n",
       "      <th>description</th>\n",
       "      <th>stars</th>\n",
       "      <th>votes</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Catalog</th>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          titles  years  plots  transcripts  genres  imdb  runtime  \\\n",
       "original                                                             \n",
       "Catalog     1102   1102   1102         1102    1102  1102     1102   \n",
       "Netflix      218    218    218          218     218   218      218   \n",
       "\n",
       "          description  stars  votes  type  \n",
       "original                                   \n",
       "Catalog          1102   1102   1102  1102  \n",
       "Netflix           218    218    218   218  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Netflix Catalog before cleaning\n",
    "df_netflix_movies.groupby(['original', 'titles'], as_index=False).count().groupby('original').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning non-English letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'ν' --> 'v'\n",
    "df_netflix_movies['transcripts'] = df_netflix_movies['transcripts'].apply(lambda x:re.sub('ν', 'v', x))\n",
    "# 'l'--> i e.g. lmp (imposible) -> There's a problem coming from the source of the transcripts itself\n",
    "# all i in upper case are treated as l (l in lower case) Fortunately most of them are pronouns like 'I' , but some words starting with 'i' in upper case are lost (small %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Raw: 0\n",
      "Max Raw: 23302\n"
     ]
    }
   ],
   "source": [
    "#raw_tokens\n",
    "df_netflix_movies['raw_tokens'] = df_netflix_movies['transcripts'].apply(lambda x:len(x.split()))\n",
    "print('Min Raw: ' + str(df_netflix_movies['raw_tokens'].min()))\n",
    "print('Max Raw: ' + str(df_netflix_movies['raw_tokens'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering transcripts out for coverage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first view to 'raw_tokens'\n",
    "# sns.boxplot(x=df_netflix_movies['raw_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a254d4fd0>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Filtering out data that don't make sense\n",
    "df_netflix_movies = df_netflix_movies[df_netflix_movies['raw_tokens']>=5400] #in general lower tokens means corrupter data. with this i'm excluding cartoons by accident though\n",
    "df_netflix_movies = df_netflix_movies[df_netflix_movies['raw_tokens']<=15000] #around 800 transcripts out\n",
    "df_netflix_movies.reset_index(drop=True, inplace=True)\n",
    "#Spotting outliers\n",
    "# q1, q3= np.percentile(df_netflix_movies['raw_tokens'],[25,75])\n",
    "# iqr = q3 - q1\n",
    "# lower_bound = q1 -(1.5 * iqr) \n",
    "# upper_bound = q3 +(1.5 * iqr) \n",
    "# print('lower_bound: '+ str(lower_bound))\n",
    "# print('upper_bound: '+ str(upper_bound))\n",
    "\n",
    "#second view to 'raw_tokens' (static boxplot)\n",
    "sns.boxplot(x=df_netflix_movies['raw_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cleaning transcripts\n",
    "from cleaning import clean_transcripts\n",
    "\n",
    "round1 = lambda x: clean_transcripts(x)\n",
    "df_netflix_movies['transcripts'] = df_netflix_movies['transcripts'].apply(round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix_movies = df_netflix_movies.assign(tokens=df_netflix_movies['transcripts'].apply(lambda x:len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>years</th>\n",
       "      <th>plots</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb</th>\n",
       "      <th>runtime</th>\n",
       "      <th>description</th>\n",
       "      <th>stars</th>\n",
       "      <th>votes</th>\n",
       "      <th>type</th>\n",
       "      <th>raw_tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Catalog</th>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          titles  years  plots  transcripts  genres  imdb  runtime  \\\n",
       "original                                                             \n",
       "Catalog      821    821    821          821       0     0        0   \n",
       "Netflix      176    176    176          176     176   176      176   \n",
       "\n",
       "          description  stars  votes  type  raw_tokens  tokens  \n",
       "original                                                       \n",
       "Catalog             0      0      0   821         821     821  \n",
       "Netflix           176    176    176   176         176     176  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Netflix Catalog after cleaning\n",
    "df_netflix_movies.groupby('original').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thrid view at 'tokens' (interative boxplot)\n",
    "# import plotly_express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_box(x=df_netflix_movies['tokens'])\n",
    "# iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Term Matrix¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "import scipy.sparse\n",
    "cv = CountVectorizer()#only misleading words excluded for the analysis\n",
    "cv_matrix = cv.fit_transform(df_netflix_movies['transcripts'])\n",
    "df_dtm = pd.DataFrame.sparse.from_spmatrix(cv_matrix, index=df_netflix_movies.index,\n",
    "                                           columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtm = df_dtm.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(indices, dtm, thousand_level=None): #, thousand_level ['4'], ['5-14']\n",
    "    \"\"\"1. The df_dtm gives the number of times a word (all_forms) shows up in an episode/movie\n",
    "       2. Then its joined to get the level and base_forms of each word\n",
    "       3. The final df has the words counted for each episode so it can be seen base_forms repetition in the final df\"\"\"\n",
    "    frames = []\n",
    "    for index in indices:\n",
    "        df_count_words = dtm[[index]].loc[dtm[index]!=0]\n",
    "        df_count_words = df_count_words.reset_index()\n",
    "        df_count_words.rename(columns={\"index\": \"all_forms\", index: \"count\"}, inplace=True)\n",
    "\n",
    "        df_count_words_level = pd.merge(df_count_words, df_nation[['base_forms', 'all_forms',\n",
    "                                'levels_frequency', 'levels', 'levels_coverage']], how='left', on='all_forms', indicator=True)\n",
    "        df_count_words_level.loc[df_count_words_level['_merge']=='left_only', 'levels_coverage'] = 100\n",
    "        if thousand_level is not None: #only consider words in specific levels\n",
    "            df_count_words_level = df_count_words_level[df_count_words_level['levels_frequency'].isin(thousand_level)]\n",
    "        frames.append(df_count_words_level)\n",
    "    df_count_words_level = pd.concat(frames)\n",
    "    return df_count_words_level\n",
    "\n",
    "\n",
    "def get_coverage(indices, df_dtm):\n",
    "    frames = []\n",
    "    for episode_index in indices:\n",
    "        df_coverage_episode = get_frames([episode_index], df_dtm) ##\n",
    "        df_coverage_episode = df_coverage_episode[['count' ,'levels_coverage']].groupby('levels_coverage').sum()\n",
    "        df_coverage_episode.drop([28, 29], axis=0, inplace=True, errors='ignore')\n",
    "        df_coverage_episode['%'] = 100 * (round(df_coverage_episode['count']/\n",
    "                                            df_coverage_episode['count'].sum(), 4))\n",
    "        df_coverage_episode = df_coverage_episode.reset_index()\n",
    "        condition = [(df_coverage_episode['levels_coverage']<=4),\n",
    "            (df_coverage_episode['levels_coverage']>=5) & (df_coverage_episode['levels_coverage']<=15),\n",
    "                    (df_coverage_episode['levels_coverage']>=26)] #15 includes list from 15 to 25\n",
    "        values = [df_coverage_episode['levels_coverage'], 5, df_coverage_episode['levels_coverage']]\n",
    "        df_coverage_episode['lvl'] = np.select(condition, values)\n",
    "        df_coverage_episode = df_coverage_episode.groupby('lvl').sum()\n",
    "        df_coverage_episode['cumulative'] = df_coverage_episode['%'].cumsum()\n",
    "        if len(indices)==1:   \n",
    "            df_coverage_episode = df_coverage_episode[['count', '%']].T.reset_index(drop=True)\n",
    "        elif len(indices)>1:\n",
    "            df_coverage_episode = df_coverage_episode[['%']].T.reset_index(drop=True)\n",
    "            df_coverage_episode['index'] = episode_index\n",
    "        frames.append(df_coverage_episode)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_coverage(df_netflix_movies.index.values, df_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary coverage in all episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistics = pd.concat(frames, axis=0, ignore_index=True)[['index', 1, 2, 3, 4, 5, 26, 27, 100]]\n",
    "#fill na values in list 27\n",
    "df_statistics[27.0].fillna(0, inplace=True)\n",
    "#assume you know interjections, character names and words created in the tv series\n",
    "df_statistics['Lvl 1'] = df_statistics[1] + df_statistics[26] + df_statistics[27] + df_statistics[100]\n",
    "df_statistics['Lvl 1+2'] = df_statistics['Lvl 1'] + df_statistics[2]\n",
    "df_statistics['Lvl 1+2+3'] = df_statistics['Lvl 1+2'] + df_statistics[3]\n",
    "df_statistics['Lvl 1+2+3+4'] = df_statistics['Lvl 1+2+3'] + df_statistics[4]\n",
    "df_statistics = pd.concat((df_netflix_movies[['titles', 'original', 'years']], df_statistics.set_index('index')), axis=1)\n",
    "df_statistics = df_statistics.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #list 100 'unique words' shouldn't be greater than 5% (words  created or only used in that tv show)\n",
    "df_statistics = df_statistics[df_statistics[100.0]<=3.5]\n",
    "df_statistics = df_statistics.sort_values(['Lvl 1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out 1 more transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistics = df_statistics[~df_statistics['titles'].str.contains('the wolfs call')] #it's not the captions but subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>years</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>26.0</th>\n",
       "      <th>27.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>Lvl 1</th>\n",
       "      <th>Lvl 1+2</th>\n",
       "      <th>Lvl 1+2+3</th>\n",
       "      <th>Lvl 1+2+3+4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Catalog</th>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          titles  years  1.0  2.0  3.0  4.0  5.0  26.0  27.0  100.0  Lvl 1  \\\n",
       "original                                                                     \n",
       "Catalog      770    770  770  770  770  770  770   770   770    770    770   \n",
       "Netflix      173    173  173  173  173  173  173   173   173    173    173   \n",
       "\n",
       "          Lvl 1+2  Lvl 1+2+3  Lvl 1+2+3+4  \n",
       "original                                   \n",
       "Catalog       770        770          770  \n",
       "Netflix       173        173          173  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Netflix Catalog after filtering (3.5%)\n",
    "df_statistics.groupby('original').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 and last 10 Originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In The Tall Grass,95.6,97.9,98.4\n",
      "A Secret Love,95.1,97.7,98.4\n",
      "Under The Riccione Sun,94.6,97.2,98.0\n",
      "Dangerous Lies,94.5,97.4,98.2\n",
      "Bird Box,94.5,97.3,98.2\n",
      "Who Would You Take To A Deserted Island,94.3,97.2,98.0\n",
      "Earthquake Bird,94.3,97.2,97.8\n",
      "Love Wedding Repeat,94.2,97.3,97.8\n",
      "Paddleton,94.2,96.9,97.6\n",
      "6 Balloons,94.2,96.8,97.1\n",
      "Winter On Fire Ukraines Fight For Freedom,87.1,94.1,97.2\n",
      "The Two Popes,87.1,92.3,95.8\n",
      "Our Planet Behind The Scenes,87.0,92.6,94.7\n",
      "Athlete A,87.0,93.2,96.6\n",
      "Peewees Big Holiday,86.7,91.0,92.0\n",
      "The Great Hack,86.3,92.6,97.2\n",
      "A Christmas Prince The Royal Baby,86.2,92.1,95.2\n",
      "Spelling The Dream,86.0,94.5,97.1\n",
      "Enter The Anime,84.9,91.5,94.6\n",
      "The Edge Of Democracy,82.3,90.9,96.2\n"
     ]
    }
   ],
   "source": [
    "#Data for Data Wrapper\n",
    "#Top 10\n",
    "for i in df_statistics[df_statistics['original']=='Netflix'][:10].values:\n",
    "    print(i[0].title()+','+str(i[11])+','+str(i[12])+','+str(i[13]))\n",
    "#Last 10\n",
    "for i in df_statistics[df_statistics['original']=='Netflix'][-10:].values:\n",
    "    print(i[0].title()+','+str(i[11])+','+str(i[12])+','+str(i[13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for ScatterPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "df_1 = df_statistics[['Lvl 1', 'titles', 'original', 'years']]\n",
    "df_1 = df_1.assign(label = 'Lvl 1')\n",
    "df_1.rename(columns={'Lvl 1':'lvl'}, inplace=True)\n",
    "df_2 = df_statistics[['Lvl 1+2', 'titles', 'original', 'years']]\n",
    "df_2 = df_2.assign(label = 'Lvl 1+2')\n",
    "df_2.rename(columns={'Lvl 1+2':'lvl'}, inplace=True)\n",
    "df_3 = df_statistics[['Lvl 1+2+3', 'titles', 'original', 'years']]\n",
    "df_3 = df_3.assign(label = 'Lvl 1+2+3')\n",
    "df_3.rename(columns={'Lvl 1+2+3':'lvl'}, inplace=True)\n",
    "# df_4 = df_statistics[['Lvl 1+2+3+4', 'season_episode_names']]\n",
    "# df_4 = df_4.assign(label = 'Lvl 1+2+3+4')\n",
    "# df_4.rename(columns={'Lvl 1+2+3+4':'lvl'}, inplace=True)\n",
    "df_dot = pd.concat([df_1, df_2, df_3])\n",
    "df_dot['lvl'] = df_dot['lvl'].apply(lambda x:round(x,1))\n",
    "df_dot.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lvl</th>\n",
       "      <th>titles</th>\n",
       "      <th>original</th>\n",
       "      <th>years</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.8</td>\n",
       "      <td>last night</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2010</td>\n",
       "      <td>Lvl 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.3</td>\n",
       "      <td>6 years</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2015</td>\n",
       "      <td>Lvl 1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.0</td>\n",
       "      <td>blood money</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2017</td>\n",
       "      <td>Lvl 1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.6</td>\n",
       "      <td>in the tall grass</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>2019</td>\n",
       "      <td>Lvl 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.3</td>\n",
       "      <td>the time travelers wife</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2009</td>\n",
       "      <td>Lvl 1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>96.2</td>\n",
       "      <td>the edge of democracy</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>2019</td>\n",
       "      <td>Lvl 1+2+3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>93.0</td>\n",
       "      <td>the first line</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2014</td>\n",
       "      <td>Lvl 1+2+3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>93.9</td>\n",
       "      <td>the wandering earth</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2019</td>\n",
       "      <td>Lvl 1+2+3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>93.0</td>\n",
       "      <td>terra</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2015</td>\n",
       "      <td>Lvl 1+2+3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>94.0</td>\n",
       "      <td>k19 the widowmaker</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2002</td>\n",
       "      <td>Lvl 1+2+3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2829 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lvl                   titles original  years      label rank\n",
       "0     96.8               last night  Catalog   2010      Lvl 1    1\n",
       "1     96.3                  6 years  Catalog   2015      Lvl 1    2\n",
       "2     96.0              blood money  Catalog   2017      Lvl 1    3\n",
       "3     95.6        in the tall grass  Netflix   2019      Lvl 1    4\n",
       "4     95.3  the time travelers wife  Catalog   2009      Lvl 1    5\n",
       "...    ...                      ...      ...    ...        ...  ...\n",
       "2824  96.2    the edge of democracy  Netflix   2019  Lvl 1+2+3    -\n",
       "2825  93.0           the first line  Catalog   2014  Lvl 1+2+3    -\n",
       "2826  93.9      the wandering earth  Catalog   2019  Lvl 1+2+3    -\n",
       "2827  93.0                    terra  Catalog   2015  Lvl 1+2+3    -\n",
       "2828  94.0       k19 the widowmaker  Catalog   2002  Lvl 1+2+3    -\n",
       "\n",
       "[2829 rows x 6 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding ranking column\n",
    "rank = df_dot.index.values\n",
    "df_dot['rank'] = rank+1\n",
    "df_dot.loc[df_dot['rank']>len(df_statistics), 'rank']='-'\n",
    "df_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data for scatterplot\n",
    "title_count = []\n",
    "for index, percentage in enumerate(df_dot['lvl']):\n",
    "    subset = df_dot.iloc[:index+1]\n",
    "    count = len(subset[subset['lvl']==percentage])\n",
    "    title_count.append(count)\n",
    "\n",
    "df_dot['count'] = title_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for ScatterPlot in DataWrapper\n",
    "# for i in df_dot.values:\n",
    "#     print(i[1].title() + ', ' + str(i[3]) + ', ' + str(i[0]) + ', ' + str(i[4]) + ', ' + str(i[2])+', '+ str(i[5])+', '+ str(i[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Netflix Originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In The Tall Grass (2019)\n",
      "A Secret Love (2020)\n",
      "Under The Riccione Sun (2020)\n",
      "Dangerous Lies (2020)\n",
      "Bird Box (2018)\n",
      "Who Would You Take To A Deserted Island (2019)\n",
      "Earthquake Bird (2019)\n",
      "Love Wedding Repeat (2020)\n",
      "Paddleton (2019)\n",
      "6 Balloons (2018)\n"
     ]
    }
   ],
   "source": [
    "for i in df_statistics[df_statistics['original']=='Netflix'][:10].values:\n",
    "    print(i[0].title()+' ('+str(i[2])+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing levels\n",
    "# list_1 = df_statistics.sort_values(1.0, ascending=False)[:100].index.values\n",
    "# list_2 = df_statistics.sort_values('Lvl 1', ascending=False)[:100].index.values\n",
    "# i = [i for i in list_1 if i in list_2]\n",
    "# len(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
